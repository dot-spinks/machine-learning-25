{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis script performs binary classification using a Quantum Support Vector Machine (QSVM)\\nimplemented with Qiskit. Unlike traditional Neural Networks, QSVM uses quantum kernels\\nto find optimal decision boundaries in a quantum feature space.\\n\\nKey concepts for beginners:\\n- QSVM: Uses quantum computing to enhance classical Support Vector Machines\\n- Quantum Kernel: Maps classical data to quantum states and measures similarity\\n- Feature Map: Circuit that encodes classical data into quantum states\\n- No training loop needed: QSVM trains in one step (unlike iterative neural networks)\\n\\nThe QSVM workflow:\\n1. Load and preprocess data (same as neural networks)\\n2. Create a quantum feature map (circuit that encodes data)\\n3. Create a quantum kernel (measures similarity between quantum states)\\n4. Train QSVM classifier (one-step process)\\n5. Evaluate and visualize results\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script performs binary classification using a Quantum Support Vector Machine (QSVM)\n",
    "implemented with Qiskit. Unlike traditional Neural Networks, QSVM uses quantum kernels\n",
    "to find optimal decision boundaries in a quantum feature space.\n",
    "\n",
    "Key concepts for beginners:\n",
    "- QSVM: Uses quantum computing to enhance classical Support Vector Machines\n",
    "- Quantum Kernel: Maps classical data to quantum states and measures similarity\n",
    "- Feature Map: Circuit that encodes classical data into quantum states\n",
    "- No training loop needed: QSVM trains in one step (unlike iterative neural networks)\n",
    "\n",
    "The QSVM workflow:\n",
    "1. Load and preprocess data (same as neural networks)\n",
    "2. Create a quantum feature map (circuit that encodes data)\n",
    "3. Create a quantum kernel (measures similarity between quantum states)\n",
    "4. Train QSVM classifier (one-step process)\n",
    "5. Evaluate and visualize results\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "QUANTUM SUPPORT VECTOR MACHINE (QSVM) FOR MUON SEED CLASSIFICATION\n",
      "================================================================================\n",
      "Loading and preprocessing data...\n",
      "Applying data quality cuts...\n",
      "Dataset shape: (92114, 12)\n",
      "First few rows of processed data:\n",
      "   expd2hitl1tk1  expd2hitl1tk2  expd2hitl1tk3  dR_L1TkMuSeedP  \\\n",
      "0       0.990987       0.713180       0.987402        0.004175   \n",
      "1       0.689316       0.764362       0.674484        0.005500   \n",
      "2       0.548451       0.480737       0.999237        0.027850   \n",
      "3       0.767553       0.994757       0.998245        0.008985   \n",
      "4       0.741779       0.999612       0.997960        0.001913   \n",
      "\n",
      "   dPhi_L1TkMuSeedP  tsos_qbp  tsos_dydz  tsos_dxdz  tsos_err0     tsos_err2  \\\n",
      "0         -0.003510 -0.023912  -0.335638  -0.038410   0.000043  6.029049e-08   \n",
      "1          0.004065  0.025677  -0.411500   0.036356   0.000068  6.829735e-08   \n",
      "2         -0.027783 -0.109400   1.075664   0.080918   0.000016  1.170655e-07   \n",
      "3         -0.008914 -0.055924   0.417587   0.080094   0.000023  6.257859e-08   \n",
      "4          0.001653  0.009154   0.334038  -0.009316   0.000005  2.613838e-08   \n",
      "\n",
      "      tsos_err5  y_label  \n",
      "0  1.060757e-07      1.0  \n",
      "1  7.030542e-08      1.0  \n",
      "2  2.279720e-07      1.0  \n",
      "3  7.708970e-08      1.0  \n",
      "4  1.955437e-08      1.0  \n",
      "\n",
      "Class distribution in full dataset:\n",
      "y_label\n",
      "0.0    51117\n",
      "1.0    40997\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################\n",
    "# Data IO part - Loading and preprocessing the muon seed classification data\n",
    "########################################################################################################\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Add parent directory to sys.path for importing custom modules\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \".\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import custom preprocessing functions from BDT_model\n",
    "from BDT_model.HLTIO import preprocess\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"QUANTUM SUPPORT VECTOR MACHINE (QSVM) FOR MUON SEED CLASSIFICATION\")\n",
    "print(\"=\"*80)\n",
    "print(\"Loading and preprocessing data...\")\n",
    "\n",
    "# Path to the original pickle file containing muon data\n",
    "pkl_path = \"./DYToLL_PU200_Spring23_NThltIter2FromL1/DYToLL_PU200_Spring23_NThltIter2FromL1_Barrel.pkl\"\n",
    "\n",
    "# Load the pickle file\n",
    "with open(pkl_path, \"rb\") as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# Extract the DataFrame from the loaded data\n",
    "df = data[0]\n",
    "\n",
    "# Apply data quality cuts\n",
    "print(\"Applying data quality cuts...\")\n",
    "# Remove unphysical pT values (pT should be positive and reasonable)\n",
    "df = df[df['gen_pt'] < 1e9]  # Remove extremely high pT values\n",
    "df = df[df['gen_pt'] > 0]    # Remove zero or negative pT values\n",
    "\n",
    "# Apply setClassLabel to compute binary class labels (0 = background, 1 = signal)\n",
    "df = preprocess.setClassLabel(df)\n",
    "\n",
    "# Compute distance features between hits and L1 tracks\n",
    "df = preprocess.addDistHitL1Tk(df, addAbsDist=False)\n",
    "\n",
    "# Apply eta cuts to focus on barrel region (|eta| < 1.2)\n",
    "df = df[((df['tsos_eta'] < 1.2) & (df['tsos_eta'] > -1.2))].copy()\n",
    "\n",
    "# Define the input features for our QSVM\n",
    "# These features describe the muon seed properties and track-hit distances\n",
    "required_columns = [\n",
    "    \"expd2hitl1tk1\",     # Expected distance to hit from L1 track 1\n",
    "    \"expd2hitl1tk2\",     # Expected distance to hit from L1 track 2  \n",
    "    \"expd2hitl1tk3\",     # Expected distance to hit from L1 track 3\n",
    "    \"dR_L1TkMuSeedP\",    # Delta R between L1 track and muon seed\n",
    "    \"dPhi_L1TkMuSeedP\",  # Delta phi between L1 track and muon seed\n",
    "    \"tsos_qbp\",          # Track state parameter: q/p (charge/momentum)\n",
    "    \"tsos_dydz\",         # Track state parameter: dy/dz slope\n",
    "    \"tsos_dxdz\",         # Track state parameter: dx/dz slope\n",
    "    \"tsos_err0\",         # Track state error parameter 0\n",
    "    \"tsos_err2\",         # Track state error parameter 2\n",
    "    \"tsos_err5\",         # Track state error parameter 5\n",
    "    \"y_label\"            # Binary class label (0=background, 1=signal)\n",
    "]\n",
    "\n",
    "# Check if all required columns exist in the dataset\n",
    "missing = [col for col in required_columns if col not in df.columns]\n",
    "if missing:\n",
    "    print(\"Warning: The following required columns are missing:\", missing)\n",
    "\n",
    "# Create final dataset with only required columns\n",
    "df_final = df[required_columns].copy()\n",
    "df_final = df_final.fillna(-1.)  # Fill missing values with -1\n",
    "\n",
    "print(f\"Dataset shape: {df_final.shape}\")\n",
    "print(\"First few rows of processed data:\")\n",
    "print(df_final.head())\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nClass distribution in full dataset:\")\n",
    "print(df_final[\"y_label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATA SAMPLING AND PREPROCESSING\n",
      "============================================================\n",
      "Randomly sampling 100 data points for QSVM training...\n",
      "Class distribution in sampled data:\n",
      "y_label\n",
      "0.0    55\n",
      "1.0    45\n",
      "Name: count, dtype: int64\n",
      "Feature matrix shape: (100, 11)\n",
      "Label vector shape: (100,)\n",
      "Training set size: 80\n",
      "Test set size: 20\n",
      "\n",
      "Standardizing features...\n",
      "Scaling parameters saved to: scalefiles/barrel_qsvm_scale.txt\n",
      "\n",
      "Final class distributions:\n",
      "Training set: [44 36]\n",
      "Test set: [11  9]\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################\n",
    "# Data sampling and preprocessing for QSVM\n",
    "########################################################################################################\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA SAMPLING AND PREPROCESSING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# For QSVM tutorial, we'll use a smaller sample of data\n",
    "# QSVM can be computationally intensive, so we start with manageable size\n",
    "sample_size = 100\n",
    "print(f\"Randomly sampling {sample_size} data points for QSVM training...\")\n",
    "\n",
    "# Randomly select indices for sampling\n",
    "np.random.seed(42)  # Set seed for reproducibility\n",
    "random_indices = np.random.choice(df_final.index, size=sample_size, replace=False)\n",
    "df_sampled = df_final.loc[random_indices]\n",
    "\n",
    "# Check class balance in sampled data\n",
    "print(\"Class distribution in sampled data:\")\n",
    "print(df_sampled[\"y_label\"].value_counts())\n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X = df_sampled.drop(columns=[\"y_label\"]).values.astype(np.float32)\n",
    "y = df_sampled[\"y_label\"].values.astype(np.int32)  # QSVM expects integer labels\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Label vector shape: {y.shape}\")\n",
    "\n",
    "# Split data into training and test sets (80% train, 20% test)\n",
    "# Stratify ensures both sets have similar class distributions\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y  # Maintain class balance in both splits\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "\n",
    "# Standardize features (important for quantum algorithms)\n",
    "# This scales all features to have mean=0 and std=1\n",
    "print(\"\\nStandardizing features...\")\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)  # Compute scaling parameters from training data only\n",
    "\n",
    "# Save scaling parameters for future use\n",
    "scalefiles_dir = \"scalefiles\"\n",
    "if not os.path.exists(scalefiles_dir):\n",
    "    os.makedirs(scalefiles_dir)\n",
    "    \n",
    "scale_filepath = os.path.join(scalefiles_dir, \"barrel_qsvm_scale.txt\")\n",
    "with open(scale_filepath, \"w\") as f_scale:\n",
    "    f_scale.write(\"%s\\n\" % str(scaler.mean_.tolist()))\n",
    "    f_scale.write(\"%s\\n\" % str(scaler.scale_.tolist()))\n",
    "print(f\"Scaling parameters saved to: {scale_filepath}\")\n",
    "\n",
    "# Apply standardization to both training and test sets\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Verify class distributions after splitting and scaling\n",
    "print(\"\\nFinal class distributions:\")\n",
    "print(f\"Training set: {np.bincount(y_train)}\")\n",
    "print(f\"Test set: {np.bincount(y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "QUANTUM SVM MODEL SETUP\n",
      "============================================================\n",
      "Setting up quantum components for QSVM...\n",
      "Creating ZZFeatureMap with 11 qubits and 2 repetitions...\n",
      "Feature map circuit created successfully!\n",
      "Circuit depth: 1\n",
      "Number of parameters: 11\n",
      "\n",
      "Setting up quantum kernel...\n",
      "Quantum kernel created successfully!\n",
      "\n",
      "Creating QSVM classifier...\n",
      "QSVM classifier created successfully!\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################\n",
    "# QSVM Model Definition using Qiskit\n",
    "########################################################################################################\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"QUANTUM SVM MODEL SETUP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Import required Qiskit and Qiskit Machine Learning modules\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit.primitives import StatevectorSampler as Sampler\n",
    "from qiskit_machine_learning.state_fidelities import ComputeUncompute\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "\n",
    "print(\"Setting up quantum components for QSVM...\")\n",
    "\n",
    "# STEP 1: Create Quantum Feature Map\n",
    "# The feature map encodes classical data into quantum states\n",
    "# ZZFeatureMap applies rotations and entangling gates based on input features\n",
    "n_features = X_train_scaled.shape[1]  # Number of input features (11 in our case)\n",
    "feature_map_reps = 2  # Number of repetitions in the feature map circuit\n",
    "\n",
    "print(f\"Creating ZZFeatureMap with {n_features} qubits and {feature_map_reps} repetitions...\")\n",
    "\n",
    "# ZZFeatureMap creates a quantum circuit that:\n",
    "# 1. Applies H gates to create superposition\n",
    "# 2. Applies RZ rotations based on input data\n",
    "# 3. Applies ZZ interactions between qubits for entanglement\n",
    "feature_map = ZZFeatureMap(\n",
    "    feature_dimension=n_features,\n",
    "    reps=feature_map_reps,\n",
    "    entanglement=\"linear\"  # Connect qubits in a linear chain\n",
    ")\n",
    "\n",
    "print(\"Feature map circuit created successfully!\")\n",
    "print(f\"Circuit depth: {feature_map.depth()}\")\n",
    "print(f\"Number of parameters: {feature_map.num_parameters}\")\n",
    "\n",
    "# STEP 2: Create Quantum Kernel\n",
    "# The quantum kernel measures similarity between quantum states\n",
    "print(\"\\nSetting up quantum kernel...\")\n",
    "\n",
    "# Create a sampler for quantum state measurement\n",
    "sampler = Sampler()\n",
    "\n",
    "# ComputeUncompute fidelity calculates overlap between quantum states\n",
    "# This measures how \"similar\" two data points are in quantum feature space\n",
    "fidelity = ComputeUncompute(sampler=sampler)\n",
    "\n",
    "# Create the quantum kernel using our feature map and fidelity measure\n",
    "quantum_kernel = FidelityQuantumKernel(\n",
    "    fidelity=fidelity,\n",
    "    feature_map=feature_map\n",
    ")\n",
    "\n",
    "print(\"Quantum kernel created successfully!\")\n",
    "\n",
    "# STEP 3: Create QSVM Classifier\n",
    "# QSVM uses the quantum kernel instead of classical kernels (like RBF)\n",
    "print(\"\\nCreating QSVM classifier...\")\n",
    "\n",
    "# QSVC is Qiskit's quantum support vector classifier\n",
    "# It works like sklearn's SVC but uses quantum kernels\n",
    "qsvm = QSVC(quantum_kernel=quantum_kernel)\n",
    "\n",
    "print(\"QSVM classifier created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING QSVM MODEL\n",
      "============================================================\n",
      "Training QSVM classifier...\n",
      "Note: Unlike neural networks, QSVM training is a one-step optimization process\n",
      "This may take several minutes depending on data size and quantum circuit complexity...\n",
      "QSVM training completed successfully!\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################\n",
    "# Training the QSVM (One-step process)\n",
    "########################################################################################################\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING QSVM MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"Training QSVM classifier...\")\n",
    "print(\"Note: Unlike neural networks, QSVM training is a one-step optimization process\")\n",
    "print(\"This may take several minutes depending on data size and quantum circuit complexity...\")\n",
    "\n",
    "# Train the QSVM classifier\n",
    "# This process:\n",
    "# 1. Computes quantum kernel matrix for all training pairs\n",
    "# 2. Solves the quadratic optimization problem to find support vectors\n",
    "# 3. Determines optimal decision boundary in quantum feature space\n",
    "qsvm.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"QSVM training completed successfully!\")\n",
    "\n",
    "# The trained model now contains:\n",
    "# - Support vectors (critical training points that define the decision boundary)\n",
    "# - Dual coefficients (weights for each support vector)\n",
    "# - Bias term (threshold for classification decisions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL EVALUATION\n",
      "============================================================\n",
      "Evaluating QSVM performance on test set...\n",
      "\n",
      "========================================\n",
      "QSVM PERFORMANCE RESULTS\n",
      "========================================\n",
      "Test Accuracy: 0.5500 (55.00%)\n",
      "ROC AUC Score: 0.9394\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background       0.55      1.00      0.71        11\n",
      "      Signal       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.55        20\n",
      "   macro avg       0.28      0.50      0.35        20\n",
      "weighted avg       0.30      0.55      0.39        20\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted\n",
      "               0       1\n",
      "Actual   0     11       0\n",
      "         1      9       0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swkim/.conda/envs/pennylane/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/swkim/.conda/envs/pennylane/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/swkim/.conda/envs/pennylane/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################\n",
    "# Model Evaluation and Performance Metrics\n",
    "########################################################################################################\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Import evaluation metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    roc_curve, roc_auc_score, precision_recall_curve, auc\n",
    ")\n",
    "\n",
    "print(\"Evaluating QSVM performance on test set...\")\n",
    "\n",
    "# Make predictions on test set\n",
    "# predict() returns class labels (0 or 1)\n",
    "y_test_pred = qsvm.predict(X_test_scaled)\n",
    "\n",
    "# For probabilistic predictions, we can use decision_function\n",
    "# This returns the distance from the decision boundary\n",
    "decision_scores = qsvm.decision_function(X_test_scaled)\n",
    "\n",
    "# Convert decision scores to probabilities using sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "y_test_prob = sigmoid(decision_scores)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_test_prob)\n",
    "\n",
    "print(f\"\\n{'='*40}\")\n",
    "print(f\"QSVM PERFORMANCE RESULTS\")\n",
    "print(f\"{'='*40}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(f\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=['Background', 'Signal']))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"                 Predicted\")\n",
    "print(f\"               0       1\")\n",
    "print(f\"Actual   0   {conf_matrix[0,0]:4d}    {conf_matrix[0,1]:4d}\")\n",
    "print(f\"         1   {conf_matrix[1,0]:4d}    {conf_matrix[1,1]:4d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CREATING VISUALIZATIONS\n",
      "============================================================\n",
      "Saving results to: ./qsvm_barrel_result\n",
      "Creating ROC curve...\n",
      "Creating confusion matrix visualization...\n",
      "Creating normalized confusion matrix...\n",
      "Creating output score distribution...\n",
      "Creating decision boundary score distribution...\n",
      "Creating precision-recall curve...\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################\n",
    "# Visualization and Results Saving\n",
    "########################################################################################################\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "# Create results directory\n",
    "results_dir = './qsvm_barrel_result'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "print(f\"Saving results to: {results_dir}\")\n",
    "\n",
    "# 1. ROC Curve\n",
    "print(\"Creating ROC curve...\")\n",
    "fpr, tpr, roc_thresholds = roc_curve(y_test, y_test_prob)\n",
    "roc_auc_val = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "         label=f'ROC curve (AUC = {roc_auc_val:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', \n",
    "         label='Random classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('QSVM ROC Curve - Muon Seed Classification', fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{results_dir}/ROC_Curve_QSVM_barrel.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 2. Confusion Matrix (Raw counts)\n",
    "print(\"Creating confusion matrix visualization...\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('QSVM Confusion Matrix - Raw Counts', fontsize=14)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(2)\n",
    "plt.xticks(tick_marks, ['Background (0)', 'Signal (1)'])\n",
    "plt.yticks(tick_marks, ['Background (0)', 'Signal (1)'])\n",
    "\n",
    "# Add text annotations\n",
    "thresh = conf_matrix.max() / 2.\n",
    "for i, j in itertools.product(range(conf_matrix.shape[0]), range(conf_matrix.shape[1])):\n",
    "    plt.text(j, i, format(conf_matrix[i, j], 'd'),\n",
    "             horizontalalignment=\"center\", fontsize=16,\n",
    "             color=\"white\" if conf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{results_dir}/Confusion_Matrix_QSVM_barrel.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 3. Normalized Confusion Matrix\n",
    "print(\"Creating normalized confusion matrix...\")\n",
    "conf_matrix_norm = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(conf_matrix_norm, interpolation='nearest', cmap=plt.cm.Greens)\n",
    "plt.title('QSVM Normalized Confusion Matrix', fontsize=14)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(2)\n",
    "plt.xticks(tick_marks, ['Background (0)', 'Signal (1)'])\n",
    "plt.yticks(tick_marks, ['Background (0)', 'Signal (1)'])\n",
    "\n",
    "# Add text annotations for normalized values\n",
    "thresh = conf_matrix_norm.max() / 2.\n",
    "for i, j in itertools.product(range(conf_matrix_norm.shape[0]), range(conf_matrix_norm.shape[1])):\n",
    "    plt.text(j, i, f\"{conf_matrix_norm[i, j]:.3f}\",\n",
    "             horizontalalignment=\"center\", fontsize=16,\n",
    "             color=\"white\" if conf_matrix_norm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{results_dir}/Normalized_Confusion_Matrix_QSVM_barrel.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 4. Output Score Distribution\n",
    "print(\"Creating output score distribution...\")\n",
    "mask_signal = (y_test == 1)\n",
    "mask_background = (y_test == 0)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(y_test_prob[mask_signal], bins=30, alpha=0.7, \n",
    "         label=f\"Signal (1) - {np.sum(mask_signal)} samples\", \n",
    "         color=\"blue\", density=True)\n",
    "plt.hist(y_test_prob[mask_background], bins=30, alpha=0.7, \n",
    "         label=f\"Background (0) - {np.sum(mask_background)} samples\", \n",
    "         color=\"red\", density=True)\n",
    "plt.axvline(x=0.5, color='black', linestyle='--', alpha=0.8, \n",
    "           label='Decision threshold (0.5)')\n",
    "plt.xlabel('QSVM Output Probability', fontsize=12)\n",
    "plt.ylabel('Density', fontsize=12)\n",
    "plt.title('QSVM Output Score Distribution', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{results_dir}/Output_Score_Distribution_QSVM_barrel.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 5. Decision Boundary Score Distribution\n",
    "print(\"Creating decision boundary score distribution...\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(decision_scores[mask_signal], bins=30, alpha=0.7, \n",
    "         label=f\"Signal (1)\", color=\"blue\", density=True)\n",
    "plt.hist(decision_scores[mask_background], bins=30, alpha=0.7, \n",
    "         label=f\"Background (0)\", color=\"red\", density=True)\n",
    "plt.axvline(x=0, color='black', linestyle='--', alpha=0.8, \n",
    "           label='Decision boundary (score=0)')\n",
    "plt.xlabel('QSVM Decision Function Score', fontsize=12)\n",
    "plt.ylabel('Density', fontsize=12)\n",
    "plt.title('QSVM Decision Function Score Distribution', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{results_dir}/Decision_Scores_Distribution_QSVM_barrel.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 6. Precision-Recall Curve\n",
    "print(\"Creating precision-recall curve...\")\n",
    "precision, recall, pr_thresholds = precision_recall_curve(y_test, y_test_prob)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, color='darkorange', lw=2,\n",
    "         label=f'PR curve (AUC = {pr_auc:.4f})')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall', fontsize=12)\n",
    "plt.ylabel('Precision', fontsize=12)\n",
    "plt.title('QSVM Precision-Recall Curve', fontsize=14)\n",
    "plt.legend(loc=\"lower left\", fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{results_dir}/Precision_Recall_Curve_QSVM_barrel.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAVING MODEL AND RESULTS\n",
      "============================================================\n",
      "QSVM model saved to: ./qsvm_barrel_result/qsvm_model_barrel.pkl\n",
      "Results summary saved to: ./qsvm_barrel_result/qsvm_results_summary.pkl\n",
      "Performance summary saved to: ./qsvm_barrel_result/qsvm_performance_summary.txt\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################\n",
    "# Save Model and Results\n",
    "########################################################################################################\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING MODEL AND RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save the trained QSVM model using pickle\n",
    "import pickle\n",
    "model_filepath = f\"{results_dir}/qsvm_model_barrel.pkl\"\n",
    "with open(model_filepath, 'wb') as f:\n",
    "    pickle.dump(qsvm, f)\n",
    "print(f\"QSVM model saved to: {model_filepath}\")\n",
    "\n",
    "# Save evaluation results\n",
    "results_summary = {\n",
    "    'model_type': 'QSVM',\n",
    "    'dataset_info': {\n",
    "        'total_samples': len(df_sampled),\n",
    "        'training_samples': len(X_train),\n",
    "        'test_samples': len(X_test),\n",
    "        'n_features': n_features,\n",
    "        'class_distribution_train': np.bincount(y_train).tolist(),\n",
    "        'class_distribution_test': np.bincount(y_test).tolist()\n",
    "    },\n",
    "    'quantum_circuit_info': {\n",
    "        'feature_map_type': 'ZZFeatureMap',\n",
    "        'n_qubits': n_features,\n",
    "        'feature_map_reps': feature_map_reps,\n",
    "        'circuit_depth': feature_map.depth(),\n",
    "        'entanglement_pattern': 'linear'\n",
    "    },\n",
    "    'performance_metrics': {\n",
    "        'accuracy': float(accuracy),\n",
    "        'roc_auc': float(roc_auc),\n",
    "        'precision_recall_auc': float(pr_auc),\n",
    "        'confusion_matrix': conf_matrix.tolist(),\n",
    "        'confusion_matrix_normalized': conf_matrix_norm.tolist()\n",
    "    },\n",
    "    'predictions': {\n",
    "        'y_test_true': y_test.tolist(),\n",
    "        'y_test_pred': y_test_pred.tolist(),\n",
    "        'y_test_prob': y_test_prob.tolist(),\n",
    "        'decision_scores': decision_scores.tolist()\n",
    "    }\n",
    "}\n",
    "\n",
    "results_filepath = f\"{results_dir}/qsvm_results_summary.pkl\"\n",
    "with open(results_filepath, 'wb') as f:\n",
    "    pickle.dump(results_summary, f)\n",
    "print(f\"Results summary saved to: {results_filepath}\")\n",
    "\n",
    "# Save a human-readable summary\n",
    "summary_filepath = f\"{results_dir}/qsvm_performance_summary.txt\"\n",
    "with open(summary_filepath, 'w') as f:\n",
    "    f.write(\"QUANTUM SUPPORT VECTOR MACHINE (QSVM) PERFORMANCE SUMMARY\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\\n\")\n",
    "    f.write(\"DATASET INFORMATION:\\n\")\n",
    "    f.write(f\"- Total samples used: {len(df_sampled)}\\n\")\n",
    "    f.write(f\"- Training samples: {len(X_train)}\\n\")\n",
    "    f.write(f\"- Test samples: {len(X_test)}\\n\")\n",
    "    f.write(f\"- Number of features: {n_features}\\n\")\n",
    "    f.write(f\"- Training class distribution: {dict(zip(['Background', 'Signal'], np.bincount(y_train)))}\\n\")\n",
    "    f.write(f\"- Test class distribution: {dict(zip(['Background', 'Signal'], np.bincount(y_test)))}\\n\\n\")\n",
    "    \n",
    "    f.write(\"QUANTUM CIRCUIT INFORMATION:\\n\")\n",
    "    f.write(f\"- Feature map: ZZFeatureMap\\n\")\n",
    "    f.write(f\"- Number of qubits: {n_features}\\n\")\n",
    "    f.write(f\"- Feature map repetitions: {feature_map_reps}\\n\")\n",
    "    f.write(f\"- Circuit depth: {feature_map.depth()}\\n\")\n",
    "    f.write(f\"- Entanglement pattern: linear\\n\\n\")\n",
    "    \n",
    "    f.write(\"PERFORMANCE METRICS:\\n\")\n",
    "    f.write(f\"- Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\\n\")\n",
    "    f.write(f\"- ROC AUC Score: {roc_auc:.4f}\\n\")\n",
    "    f.write(f\"- Precision-Recall AUC: {pr_auc:.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"CONFUSION MATRIX:\\n\")\n",
    "    f.write(f\"                 Predicted\\n\")\n",
    "    f.write(f\"               Background  Signal\\n\")\n",
    "    f.write(f\"Actual Background  {conf_matrix[0,0]:6d}    {conf_matrix[0,1]:6d}\\n\")\n",
    "    f.write(f\"       Signal      {conf_matrix[1,0]:6d}    {conf_matrix[1,1]:6d}\\n\")\n",
    "\n",
    "print(f\"Performance summary saved to: {summary_filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pennylane",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
